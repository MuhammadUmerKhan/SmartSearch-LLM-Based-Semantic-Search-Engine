# ğŸ“ŒSmartSearch: LLM-Based Semantic Search Engine

## ğŸš€ Introduction
The **AI-Powered Search Engine** is a web-based application that combines **Google Search API**, **web scraping**, **FAISS vector database**, **LLMs**, and **custom URL search** to fetch, extract, and summarize real-time search results. This tool is designed to **enhance information retrieval** by providing structured, AI-generated responses from both web results and custom URL inputs.

![](https://cdn.builtin.com/cdn-cgi/image/f=auto,fit=cover,w=1200,h=635,q=80/https://builtin.com/sites/www.builtin.com/files/2024-06/AI%20search%20engine.jpg)
---

### ğŸ”¹ **Key Features**
- **ğŸ” Real-time Web Search**: Fetches search results via **Google Custom Search API**.
- **ğŸ“„ Article Extraction**: Scrapes full-text articles from links.
- **ğŸŒ Custom URL Search**: Allows users to input URLs for content extraction and indexing.
- **ğŸ§  FAISS Vector Database**: Stores and retrieves key content.
- **ğŸ¤– AI-Powered Answering**: Uses **Llama 3** via **LangChain** to generate structured answers.
- **ğŸš€ Streamlit UI**: Provides an interactive and user-friendly interface.


---

## ğŸ“‚ **Project Structure & File Explanations**
```
AI_Search_Engine/
â”‚
â”œâ”€â”€ app.py                    # ğŸ¨ Streamlit UI for User Interaction
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ AI_Powered_Search_Engine.ipynb  # ğŸ“š Jupyter Notebook for Experimentation
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.py              # âš™ï¸ API Keys & Global Configurations
â”‚
â”œâ”€â”€ search/
â”‚   â”œâ”€â”€ google_search.py       # ğŸ” Google Search API Handling
â”‚   â”œâ”€â”€ scraper.py             # ğŸ“„ Web Scraping & Article Extraction
â”‚
â”œâ”€â”€ vector_store/
â”‚   â”œâ”€â”€ vector_store.py        # ğŸ“š FAISS Vector Database Handling
â”‚
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ llm_handler.py         # ğŸ¤– LLM Query Processing
â”‚
â”œâ”€â”€ pp_pages/
â”‚   â”œâ”€â”€ custom_urls.py         # ğŸŒ Custom URL Search Handler
â”‚   â”œâ”€â”€ home.py                # ğŸ  Home Page
â”‚   â”œâ”€â”€ instruction.py         # ğŸ“œ Search Engine Instructions
â”‚   â”œâ”€â”€ search_engine.py       # ğŸ” Search Engine Implementation
â”‚   â”œâ”€â”€ doc_chat.py            # ğŸ“œ Chat with documents
â”‚
â”œâ”€â”€ requirements.txt           # ğŸ“¦ Dependencies for the Project
â”‚
â”œâ”€â”€ .env                       # Stores API keys (Not shared for security)
â”‚
â””â”€â”€ README.md                  # ğŸ“– Project Documentation & Setup Guide
```

### **ğŸ“œ File Explanations**

#### 1ï¸âƒ£ **`config.py` - Configuration File**
- Loads **API keys** and project constants from `.env`.
- Stores:
  - `GOOGLE_SEARCH_KEY` (Google API Key)
  - `SEARCH_ENGINE_ID` (Custom Search Engine ID)
  - `GROQ_API_KEY` (LLM API Key)
  - `CHUNK_SIZE`, `CHUNK_OVERLAP`, `MAX_LENGTH`, and `TOP_K_RESULTS`

#### 2ï¸âƒ£ **`google_search.py` - Google Search API Integration**
- Calls **Google Custom Search API** to fetch top results.
- Uses caching to avoid repeated API calls.
- Implements **exponential backoff retry mechanism** for rate limits.

#### 3ï¸âƒ£ **`scraper.py` - Web Scraper**
- Uses `newspaper3k` to extract full article text from URLs.
- Limits text to **5000 characters** to avoid unnecessary large responses.
- Handles exceptions for failed extractions.

#### 4ï¸âƒ£ **`vector_store.py` - FAISS Vector Database**
- Uses **HuggingFace Embeddings (`all-MiniLM-L6-v2`)**.
- Splits extracted text into **overlapping chunks**.
- Stores **embeddings** in a FAISS vector database for efficient retrieval.

#### 5ï¸âƒ£ **`llm_handler.py` - LLM Query Processor**
- Calls **DIFFERENT** via **LangChain-Groq API**.
- Takes user query + relevant text chunks â†’ **generates AI response**.
- Formats responses into **structured bullet points with emojis**.

#### 6ï¸âƒ£ **`home.py` - Streamlit Home Page**
- Displays an **introduction**, **features**, and **GitHub/LinkedIn links**.
- Provides **user instructions** on how to use the app.

#### 7ï¸âƒ£ **`app.py` - Main Streamlit UI**
- Implements **Sidebar Navigation**.
- Accepts user query â†’ Fetches search results â†’ Extracts articles â†’ Creates a vector DB â†’ Calls LLM for response.
- Displays:
  - **AI-generated structured answer**
  - **List of sources with clickable links**

#### 8ï¸âƒ£ **`custom_urls.py` - Custom URL Search Handler**
- Allows users to **input URLs** for content extraction.
- Extracted content is indexed into a **FAISS vector database**.
- Users can search using this custom content, enhancing search results.


---
## **ğŸ¤– Supported LLMs**
| Model | API Name |
|--------|-------------------------------|
| Llama | `llama-3.3-70b-versatile` |
| Gemma | `gemma2-9b-it` |
| Qwen | `qwen-qwq-32b` |
| DeepSeek | `deepseek-r1-distill-qwen-32b` |
| Llama 4 | `meta-llama/llama-4-scout-17b-16e-instruct` |

---
## ğŸ›  **Setup & Installation**

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/MuhammadUmerKhan/AI-Powered-Semantic-Search-Engine-with-LLMs-Vector-Databases.git
cd AI-Powered-Semantic-Search-Engine-with-LLMs-Vector-Databases
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set Up API Keys**
To use the search engine, you'll need to set up the following API keys. Create a `.env` file in the root directory of your project and add the following variables:

```env
GOOGLE_SEARCH_API_KEY=your_google_api_key           # Google Search API key (Generate from: https://cse.google.com/cse/all)
SEARCH_ENGINE_ID=your_search_engine_id              # Search engine ID (Generate from: Copy ID after creating engine)
LANGCHAIN_GROK_API_KEY=your_llm_api_key            # Langchain Grok API key (Generate from: https://console.groq.com/)
HUGGINGFACE_LOGIN_API_KEY=your_huggingface_api_key  # Huggingface Logging API key (Generate from: https://huggingface.co/)
```

**Where to Get the Keys:**
- **Google Search API Key**: [Generate from Google](https://cse.google.com/cse/all)
- **Search Engine ID**: After creating your custom search engine on Google, you can find your Search Engine ID. Just copy it from the CSE control panel.
- **LangChain Grok API Key**: [Generate from LangChain Console](https://console.groq.com/)
- **Huggingface Login API Key**: [Generate from HuggingFace](https://huggingface.co/)


### **4ï¸âƒ£ Run the Application**
```bash
streamlit run app.py
```

---

## ğŸ¯ **Usage Guide**
### ğŸ” **How to Use the AI-Powered Search Engine**
1ï¸âƒ£ **Navigate to the Home Page** â†’ Read about features & how it works.  
2ï¸âƒ£ **Go to the Search Page** â†’ Enter a query in the search box or input URLs to add custom content.  
3ï¸âƒ£ **Press Enter** â†’ The app will fetch, extract, process, and generate AI responses.  
4ï¸âƒ£ **View AI Response & Sources** â†’ Click links for more details.

### ğŸŒ **Using Custom URL-Based Search**
1ï¸âƒ£ **Enter a URL** in the provided text area.  
2ï¸âƒ£ **Click "Extract & Search"** to index content from the URL.  
3ï¸âƒ£ Use the search box to query the indexed URL content for AI-generated answers.

ğŸ“Œ **Example Queries:**
- *"What are the latest advancements in AI?"*
- *"Explain quantum computing in simple terms."*
- *"What are the benefits of intermittent fasting?"*

---

## ğŸ³ **Dockerization & Deployment**

You can easily run this project using Docker and share or deploy it from Docker Hub.

### âœ… **Build the Docker Image**

Make sure your `Dockerfile` is correctly set up. Then run:

```bash
docker build -t muhammadumerkhan/semantic-engine .
```

### ğŸš€ **Run the Docker Container**

```bash
docker run -p 8501:8501 muhammadumerkhan/semantic-engine
```

> This will launch the Streamlit/ FastAPI interface on `http://localhost:8501` depending on your app entrypoint.

### ğŸ“¤ **Push to Docker Hub**

First, log in to Docker:

```bash
docker login
```

Then push your image:

```bash
docker push muhammadumerkhan/semantic-engine
```

### ğŸ“¥ **Pull & Run from Docker Hub**

Anyone can pull and run the app using:

```bash
docker pull muhammadumerkhan/semantic-engine
docker run -p 8501:8501 muhammadumerkhan/semantic-engine
```

---

## ğŸ”¥ **Tech Stack**
âœ… **Python** - Main programming language.  
âœ… **Streamlit** - Frontend UI framework.  
âœ… **Google Custom Search API** - Fetches search results.  
âœ… **Newspaper3k** - Extracts article content.  
âœ… **FAISS** - Vector storage for fast retrieval.  
âœ… **LangChain & Llama 3** - LLM for generating AI-powered responses.  
âœ… **Custom URL Search** - Indexes and searches user-provided URLs.

---

## ğŸ“Œ **To-Do & Future Improvements**
âœ… Implement caching & retries for API requests.  
âœ… Improve LLM response formatting with markdown & bullet points.  
ğŸ”œ Add **user feedback mechanism** to improve responses.  
ğŸ”œ Support **multiple search APIs** for better coverage.  
ğŸ”œ Implement **document upload** for personalized search.  

---

## ğŸ”´ Live Demo:
- [Web App](https://ai-powered-search-engine-with-llms.streamlit.app/?embed_options=show_toolbar,dark_theme,show_colored_line,show_footer)
---

## ğŸ‘¨â€ğŸ’» **Author & Contact**
ğŸ’¡ **Developed by:** [Muhammad Umer Khan](https://www.linkedin.com/in/muhammad-umer-khan-61729b260/)  
ğŸ“§ **Contact:** Reach out via LinkedIn or GitHub.  

ğŸŒŸ **If you found this project helpful, give it a â­ on GitHub!** ğŸš€
